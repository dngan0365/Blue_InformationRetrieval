{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e29aa012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "from pyvi import ViTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bc97377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIG ===\n",
    "DOCS_PATH = \"../1.CollectingDocuments/data_clean\"\n",
    "LINK_FILE = \"../1.CollectingDocuments/extracted_urls.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe26488d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ ƒêang t·∫£i v√† x·ª≠ l√Ω t√†i li·ªáu...\n",
      "‚úÖ ƒê√£ x·ª≠ l√Ω 406 t√†i li·ªáu.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === 1Ô∏è‚É£ ƒê·ªçc d·ªØ li·ªáu v√† ti·ªÅn x·ª≠ l√Ω ===\n",
    "def clean_text(text):\n",
    "    # Lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát, gi·ªØ l·∫°i ti·∫øng Vi·ªát c√≥ d·∫•u\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)  # b·ªè URL\n",
    "    text = re.sub(r\"[^a-zA-Z√Ä-·ªπ0-9\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text.lower()\n",
    "\n",
    "def load_and_preprocess_docs(folder_path):\n",
    "    docs = {}\n",
    "    for fname in os.listdir(folder_path):\n",
    "        if fname.endswith(\".txt\"):\n",
    "            with open(os.path.join(folder_path, fname), \"r\", encoding=\"utf-8\") as f:\n",
    "                raw = f.read()\n",
    "            clean = clean_text(raw)\n",
    "            tokens = ViTokenizer.tokenize(clean)\n",
    "            docs[fname] = tokens\n",
    "    return docs\n",
    "\n",
    "print(\"üîÑ ƒêang t·∫£i v√† x·ª≠ l√Ω t√†i li·ªáu...\")\n",
    "docs = load_and_preprocess_docs(DOCS_PATH)\n",
    "print(f\"‚úÖ ƒê√£ x·ª≠ l√Ω {len(docs)} t√†i li·ªáu.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "836355bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Th·ªëng k√™ c∆° b·∫£n:\n",
      "                                             document  total_words  \\\n",
      "0  15_ia_iem_du_lich_Buon_Ma_Thuot_ep_quen_loi_ve...         1807   \n",
      "1  3_ngoi_lang_co_nep_minh_giua_long_cao_nguyen_a...          952   \n",
      "2               ao_Binh_Ba__Wikipedia_tieng_Viet.txt          483   \n",
      "3  ao_Hon_Khoai_o_Ca_Mau_-_vung_bien_va_dai_at_ph...         2553   \n",
      "4                    a_Lat__Wikipedia_tieng_Viet.txt        15349   \n",
      "\n",
      "   unique_words                                          top_words  \n",
      "0           646  kh√°ch_s·∫°n, bu√¥n, du_l·ªãch, c·ªßa, l√†, thu·ªôt, ma, ...  \n",
      "1           503  c·ªßa, l√†ng, l√¥, nh·ªØng, ng√¥i, ƒë√°, kh√°ch, v·ªõi, l√†...  \n",
      "2           252  b√¨nh, ba, ƒë·∫£o, l√†, ng√†y, th√°ng, nƒÉm, 2013, b√£i...  \n",
      "3           749  du_l·ªãch, ƒë·∫£o, ch√¢u, h√≤n, b√¨nh, tour, khoai, ni...  \n",
      "4          2646  nƒÉm, v√†, l·∫°t, ƒë√†, th√°ng, ng√†y, c·ªßa, th√†nh_ph·ªë,...   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === 2Ô∏è‚É£ Ph√¢n t√≠ch th·ªëng k√™ c∆° b·∫£n ===\n",
    "doc_stats = []\n",
    "for fname, text in docs.items():\n",
    "    tokens = text.split()\n",
    "    total_words = len(tokens)\n",
    "    unique_words = len(set(tokens))\n",
    "    top_words = [w for w, _ in Counter(tokens).most_common(10)]\n",
    "    doc_stats.append({\n",
    "        \"document\": fname,\n",
    "        \"total_words\": total_words,\n",
    "        \"unique_words\": unique_words,\n",
    "        \"top_words\": \", \".join(top_words)\n",
    "    })\n",
    "\n",
    "df_stats = pd.DataFrame(doc_stats)\n",
    "print(\"üìä Th·ªëng k√™ c∆° b·∫£n:\\n\", df_stats.head(), \"\\n\")\n",
    "\n",
    "# === 3Ô∏è‚É£ TF-IDF cho to√†n b·ªô t·∫≠p t√†i li·ªáu ===\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "tfidf_matrix = vectorizer.fit_transform(docs.values())\n",
    "feature_names = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8df6b499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tr√≠ch 5 t·ª´ c√≥ TF-IDF cao nh·∫•t cho m·ªói doc\n",
    "def top_tfidf_words(row, features, top_n=5):\n",
    "    idx = row.nonzero()[1]\n",
    "    scores = zip(idx, [row[0, i] for i in idx])\n",
    "    sorted_words = sorted(scores, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    return \", \".join([features[i] for i, _ in sorted_words])\n",
    "\n",
    "top_tfidf = [top_tfidf_words(tfidf_matrix[i], feature_names) for i in range(len(docs))]\n",
    "df_stats[\"top_tfidf\"] = top_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67298b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>total_words</th>\n",
       "      <th>unique_words</th>\n",
       "      <th>top_words</th>\n",
       "      <th>top_tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15_ia_iem_du_lich_Buon_Ma_Thuot_ep_quen_loi_ve...</td>\n",
       "      <td>1807</td>\n",
       "      <td>646</td>\n",
       "      <td>kh√°ch_s·∫°n, bu√¥n, du_l·ªãch, c·ªßa, l√†, thu·ªôt, ma, ...</td>\n",
       "      <td>bu√¥n, st, thu·ªôt, ma, kh√°ch_s·∫°n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3_ngoi_lang_co_nep_minh_giua_long_cao_nguyen_a...</td>\n",
       "      <td>952</td>\n",
       "      <td>503</td>\n",
       "      <td>c·ªßa, l√†ng, l√¥, nh·ªØng, ng√¥i, ƒë√°, kh√°ch, v·ªõi, l√†...</td>\n",
       "      <td>l√¥, l√†ng, l≈©ng, c·ªï_k√≠nh, t∆∞·ªùng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ao_Binh_Ba__Wikipedia_tieng_Viet.txt</td>\n",
       "      <td>483</td>\n",
       "      <td>252</td>\n",
       "      <td>b√¨nh, ba, ƒë·∫£o, l√†, ng√†y, th√°ng, nƒÉm, 2013, b√£i...</td>\n",
       "      <td>2013, ƒë·∫£o, b√¨nh, ba, truy_c·∫≠p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ao_Hon_Khoai_o_Ca_Mau_-_vung_bien_va_dai_at_ph...</td>\n",
       "      <td>2553</td>\n",
       "      <td>749</td>\n",
       "      <td>du_l·ªãch, ƒë·∫£o, ch√¢u, h√≤n, b√¨nh, tour, khoai, ni...</td>\n",
       "      <td>khoai, ƒë·∫£o, h√≤n, du_l·ªãch, ch√¢u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a_Lat__Wikipedia_tieng_Viet.txt</td>\n",
       "      <td>15349</td>\n",
       "      <td>2646</td>\n",
       "      <td>nƒÉm, v√†, l·∫°t, ƒë√†, th√°ng, ng√†y, c·ªßa, th√†nh_ph·ªë,...</td>\n",
       "      <td>l·∫°t, tr·∫ßn_s·ªπ, ƒë√†, tr, nƒÉm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document  total_words  \\\n",
       "0  15_ia_iem_du_lich_Buon_Ma_Thuot_ep_quen_loi_ve...         1807   \n",
       "1  3_ngoi_lang_co_nep_minh_giua_long_cao_nguyen_a...          952   \n",
       "2               ao_Binh_Ba__Wikipedia_tieng_Viet.txt          483   \n",
       "3  ao_Hon_Khoai_o_Ca_Mau_-_vung_bien_va_dai_at_ph...         2553   \n",
       "4                    a_Lat__Wikipedia_tieng_Viet.txt        15349   \n",
       "\n",
       "   unique_words                                          top_words  \\\n",
       "0           646  kh√°ch_s·∫°n, bu√¥n, du_l·ªãch, c·ªßa, l√†, thu·ªôt, ma, ...   \n",
       "1           503  c·ªßa, l√†ng, l√¥, nh·ªØng, ng√¥i, ƒë√°, kh√°ch, v·ªõi, l√†...   \n",
       "2           252  b√¨nh, ba, ƒë·∫£o, l√†, ng√†y, th√°ng, nƒÉm, 2013, b√£i...   \n",
       "3           749  du_l·ªãch, ƒë·∫£o, ch√¢u, h√≤n, b√¨nh, tour, khoai, ni...   \n",
       "4          2646  nƒÉm, v√†, l·∫°t, ƒë√†, th√°ng, ng√†y, c·ªßa, th√†nh_ph·ªë,...   \n",
       "\n",
       "                        top_tfidf  \n",
       "0  bu√¥n, st, thu·ªôt, ma, kh√°ch_s·∫°n  \n",
       "1  l√¥, l√†ng, l≈©ng, c·ªï_k√≠nh, t∆∞·ªùng  \n",
       "2   2013, ƒë·∫£o, b√¨nh, ba, truy_c·∫≠p  \n",
       "3  khoai, ƒë·∫£o, h√≤n, du_l·ªãch, ch√¢u  \n",
       "4       l·∫°t, tr·∫ßn_s·ªπ, ƒë√†, tr, nƒÉm  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7a7259",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'source'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mt200\\OneDrive\\Desktop\\AI\\InformationRetrieval\\Project_InformationRetrieval\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'source'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m G = nx.DiGraph()\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m links.iterrows():\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     src, tgt = \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msource\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, row[\u001b[33m\"\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m src \u001b[38;5;129;01min\u001b[39;00m docs \u001b[38;5;129;01mand\u001b[39;00m tgt \u001b[38;5;129;01min\u001b[39;00m docs:\n\u001b[32m      8\u001b[39m         G.add_edge(src, tgt)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mt200\\OneDrive\\Desktop\\AI\\InformationRetrieval\\Project_InformationRetrieval\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:1133\u001b[39m, in \u001b[36mSeries.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[key]\n\u001b[32m   1132\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[32m-> \u001b[39m\u001b[32m1133\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1135\u001b[39m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[32m   1136\u001b[39m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[32m   1137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mt200\\OneDrive\\Desktop\\AI\\InformationRetrieval\\Project_InformationRetrieval\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:1249\u001b[39m, in \u001b[36mSeries._get_value\u001b[39m\u001b[34m(self, label, takeable)\u001b[39m\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[label]\n\u001b[32m   1248\u001b[39m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1249\u001b[39m loc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1251\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[32m   1252\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[loc]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mt200\\OneDrive\\Desktop\\AI\\InformationRetrieval\\Project_InformationRetrieval\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'source'"
     ]
    }
   ],
   "source": [
    "# # === 4Ô∏è‚É£ Ph√¢n t√≠ch li√™n k·∫øt & t√≠nh PageRank ===\n",
    "# if os.path.exists(LINK_FILE):\n",
    "#     links = pd.read_csv(LINK_FILE)\n",
    "#     G = nx.DiGraph()\n",
    "#     for _, row in links.iterrows():\n",
    "#         src, tgt = row[\"source_file\"], row[\"target\"]\n",
    "#         if src in docs and tgt in docs:\n",
    "#             G.add_edge(src, tgt)\n",
    "    \n",
    "#     # T√≠nh PageRank (ƒë·ªô ph·ªï bi·∫øn / ·∫£nh h∆∞·ªüng)\n",
    "#     pagerank_scores = nx.pagerank(G, alpha=0.85)\n",
    "#     df_stats[\"pagerank\"] = df_stats[\"document\"].map(pagerank_scores).fillna(0)\n",
    "# else:\n",
    "#     df_stats[\"pagerank\"] = 0\n",
    "#     print(\"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file li√™n k·∫øt, b·ªè qua PageRank.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb4ed6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'pagerank'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_23932\\1103236172.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# === 5Ô∏è‚É£ Chu·∫©n h√≥a d·ªØ li·ªáu t·ªïng h·ª£p ===\u001b[39;00m\n\u001b[32m      2\u001b[39m df_stats[\u001b[33m\"avg_tfidf\"\u001b[39m] = tfidf_matrix.mean(axis=\u001b[32m1\u001b[39m).A1\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m df_stats = df_stats.sort_values(by=\u001b[33m\"pagerank\"\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      4\u001b[39m \n\u001b[32m      5\u001b[39m print(\u001b[33m\"üèÅ K·∫øt qu·∫£ t·ªïng h·ª£p:\"\u001b[39m)\n\u001b[32m      6\u001b[39m print(df_stats.head())\n",
      "\u001b[32mc:\\Users\\mt200\\OneDrive\\Desktop\\AI\\InformationRetrieval\\Project_InformationRetrieval\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[39m\n\u001b[32m   7207\u001b[39m             )\n\u001b[32m   7208\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m len(by):\n\u001b[32m   7209\u001b[39m             \u001b[38;5;66;03m# len(by) == 1\u001b[39;00m\n\u001b[32m   7210\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m7211\u001b[39m             k = self._get_label_or_level_values(by[\u001b[32m0\u001b[39m], axis=axis)\n\u001b[32m   7212\u001b[39m \n\u001b[32m   7213\u001b[39m             \u001b[38;5;66;03m# need to rewrap column in Series to apply key function\u001b[39;00m\n\u001b[32m   7214\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[32mc:\\Users\\mt200\\OneDrive\\Desktop\\AI\\InformationRetrieval\\Project_InformationRetrieval\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1910\u001b[39m             values = self.xs(key, axis=other_axes[\u001b[32m0\u001b[39m])._values\n\u001b[32m   1911\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m self._is_level_reference(key, axis=axis):\n\u001b[32m   1912\u001b[39m             values = self.axes[axis].get_level_values(key)._values\n\u001b[32m   1913\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m KeyError(key)\n\u001b[32m   1915\u001b[39m \n\u001b[32m   1916\u001b[39m         \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[32m   1917\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m values.ndim > \u001b[32m1\u001b[39m:\n",
      "\u001b[31mKeyError\u001b[39m: 'pagerank'"
     ]
    }
   ],
   "source": [
    "# === 5Ô∏è‚É£ Chu·∫©n h√≥a d·ªØ li·ªáu t·ªïng h·ª£p ===\n",
    "df_stats[\"avg_tfidf\"] = tfidf_matrix.mean(axis=1).A1\n",
    "# df_stats = df_stats.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e3ff3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÅ K·∫øt qu·∫£ t·ªïng h·ª£p:\n",
      "                                            document  total_words  \\\n",
      "0  15_ia_iem_du_lich_Buon_Ma_Thuot_ep_quen_loi_ve...         1807   \n",
      "1  3_ngoi_lang_co_nep_minh_giua_long_cao_nguyen_a...          952   \n",
      "2               ao_Binh_Ba__Wikipedia_tieng_Viet.txt          483   \n",
      "3  ao_Hon_Khoai_o_Ca_Mau_-_vung_bien_va_dai_at_ph...         2553   \n",
      "4                    a_Lat__Wikipedia_tieng_Viet.txt        15349   \n",
      "\n",
      "   unique_words                                          top_words  \\\n",
      "0           646  kh√°ch_s·∫°n, bu√¥n, du_l·ªãch, c·ªßa, l√†, thu·ªôt, ma, ...   \n",
      "1           503  c·ªßa, l√†ng, l√¥, nh·ªØng, ng√¥i, ƒë√°, kh√°ch, v·ªõi, l√†...   \n",
      "2           252  b√¨nh, ba, ƒë·∫£o, l√†, ng√†y, th√°ng, nƒÉm, 2013, b√£i...   \n",
      "3           749  du_l·ªãch, ƒë·∫£o, ch√¢u, h√≤n, b√¨nh, tour, khoai, ni...   \n",
      "4          2646  nƒÉm, v√†, l·∫°t, ƒë√†, th√°ng, ng√†y, c·ªßa, th√†nh_ph·ªë,...   \n",
      "\n",
      "                        top_tfidf  avg_tfidf  \n",
      "0  bu√¥n, st, thu·ªôt, ma, kh√°ch_s·∫°n   0.002573  \n",
      "1  l√¥, l√†ng, l≈©ng, c·ªï_k√≠nh, t∆∞·ªùng   0.002975  \n",
      "2   2013, ƒë·∫£o, b√¨nh, ba, truy_c·∫≠p   0.002092  \n",
      "3  khoai, ƒë·∫£o, h√≤n, du_l·ªãch, ch√¢u   0.003164  \n",
      "4       l·∫°t, tr·∫ßn_s·ªπ, ƒë√†, tr, nƒÉm   0.003262  \n"
     ]
    }
   ],
   "source": [
    "print(\"üèÅ K·∫øt qu·∫£ t·ªïng h·ª£p:\")\n",
    "print(df_stats.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d32442b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o output/doc_analysis.csv\n"
     ]
    }
   ],
   "source": [
    "# === 6Ô∏è‚É£ Xu·∫•t ra file t·ªïng h·ª£p ===\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "df_stats.to_csv(\"output/doc_analysis.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"\\nüíæ ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o output/doc_analysis.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
