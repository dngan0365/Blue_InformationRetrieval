{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d46cd99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from datasketch import MinHash\n",
    "from itertools import combinations\n",
    "from nltk import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08984808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== Cấu hình ======\n",
    "FOLDER_PATH = \"../1.CollectingDocuments/data_clean\"  # Thư mục chứa các file .txt\n",
    "NGRAMS = [2, 3]       # Dùng bigram và trigram\n",
    "MINHASH_SIZE = 128    # Số lượng hash (kích thước vector minhash)\n",
    "SIM_THRESHOLD = 0.5   # Ngưỡng tương tự để xem là trùng\n",
    "ENCODING = \"utf-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47a55be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== 1. Làm sạch text ======\n",
    "def clean_text(text):\n",
    "    \"\"\"Chuyển chữ thường, bỏ ký tự đặc biệt, giữ lại chữ & số.\"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82e5283d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== 2. Sinh n-gram ======\n",
    "def get_ngrams(text, n):\n",
    "    \"\"\"Trả về danh sách các n-gram (chuỗi n từ liên tiếp).\"\"\"\n",
    "    tokens = word_tokenize(text)\n",
    "    return [\" \".join(gram) for gram in ngrams(tokens, n)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "425c2c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== 3. Tạo MinHash ======\n",
    "def create_minhash(ngrams_set, num_perm=MINHASH_SIZE):\n",
    "    \"\"\"Sinh chữ ký MinHash từ tập n-gram.\"\"\"\n",
    "    m = MinHash(num_perm=num_perm)\n",
    "    for ng in ngrams_set:\n",
    "        m.update(ng.encode(\"utf8\"))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48928b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== 4. Đọc các file trong thư mục ======\n",
    "def load_documents(folder):\n",
    "    docs = {}\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            path = os.path.join(folder, filename)\n",
    "            with open(path, \"r\", encoding=ENCODING) as f:\n",
    "                text = f.read()\n",
    "                docs[filename] = text\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c23ce68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== 5. Tiền xử lý + sinh MinHash cho từng doc ======\n",
    "def build_minhashes(docs):\n",
    "    minhashes = {}\n",
    "    for name, text in tqdm(docs.items(), desc=\"Tạo MinHash\"):\n",
    "        text = clean_text(text)\n",
    "        ngrams_all = set()\n",
    "        for n in NGRAMS:\n",
    "            ngrams_all |= set(get_ngrams(text, n))\n",
    "        minhashes[name] = create_minhash(ngrams_all)\n",
    "    return minhashes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5c1fcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== 6. So sánh cặp tài liệu ======\n",
    "def compute_similarities(minhashes, threshold=SIM_THRESHOLD):\n",
    "    similar_pairs = []\n",
    "    for (doc1, m1), (doc2, m2) in tqdm(list(combinations(minhashes.items(), 2)), desc=\"So sánh\"):\n",
    "        sim = m1.jaccard(m2)\n",
    "        if sim >= threshold:\n",
    "            similar_pairs.append((doc1, doc2, round(sim, 3)))\n",
    "    return similar_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20d82713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== 7. Ghi kết quả ra CSV ======\n",
    "def save_results(pairs, output_path=\"similar_docs.csv\"):\n",
    "    import csv\n",
    "    with open(output_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"Document 1\", \"Document 2\", \"Similarity\"])\n",
    "        for d1, d2, s in pairs:\n",
    "            writer.writerow([d1, d2, s])\n",
    "    print(f\"✅ Kết quả đã lưu vào {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d00dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Đang đọc file...\n",
      "📄 Tổng số tài liệu: 407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tạo MinHash: 100%|██████████| 407/407 [02:42<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Đang tính độ tương tự...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "So sánh: 100%|██████████| 82621/82621 [00:01<00:00, 48146.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧭 Các cặp tài liệu trùng hoặc giống nhau:\n",
      " - Cam_nang_du_lich_Ky_Co.txt <-> Cam_nang_du_lich_Lam_ong.txt: độ tương tự = 1.0\n",
      "✅ Kết quả đã lưu vào similar_docs.csv\n"
     ]
    }
   ],
   "source": [
    "# ====== 8. Chạy toàn bộ pipeline ======\n",
    "print(\"📂 Đang đọc file...\")\n",
    "docs = load_documents(FOLDER_PATH)\n",
    "\n",
    "print(f\"📄 Tổng số tài liệu: {len(docs)}\")\n",
    "minhashes = build_minhashes(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4bc1bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Đang tính độ tương tự...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "So sánh: 100%|██████████| 82621/82621 [00:01<00:00, 52337.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🧭 Các cặp tài liệu trùng hoặc giống nhau:\n",
      " - Cam_nang_du_lich_Hung_Yen.txt <-> Cam_nang_du_lich_Ninh_Chu.txt: độ tương tự = 0.648\n",
      " - Cam_nang_du_lich_Ky_Co.txt <-> Cam_nang_du_lich_Lam_ong.txt: độ tương tự = 1.0\n",
      " - Cam_nang_du_lich_Ninh_Chu.txt <-> Cam_nang_du_lich_Thai_Binh.txt: độ tương tự = 0.523\n",
      " - Cam_nang_du_lich_Quang_Binh.txt <-> Cam_nang_du_lich_Quang_Tri.txt: độ tương tự = 0.5\n",
      " - Chiem_nguong_ve_ep_hiem_co_o_Thac_Mo_Binh_Phuoc_-_HoaBinhTourist.txt <-> Thac_Mo_Binh_Phuoc_Kham_pha_ve_ep_hiem_co_kho_tim.txt: độ tương tự = 0.539\n",
      " - Hang_En__Wikipedia_tieng_Viet.txt <-> ong_Phong_Nha__Wikipedia_tieng_Viet.txt: độ tương tự = 0.539\n",
      " - Khu_Du_Lich_Buu_Long,_Toa_o_Vui_Choi_Cuc_Hot_Gan_Sai_Gon_-_Klook_Blog.txt <-> Kinh_Nghiem_i_ia_ao_Cu_Chi,_Di_Tich_Noi_Tieng_O_Sai_Gon_-_Klook_Blog.txt: độ tương tự = 0.609\n",
      " - Thac_amb'ri__Wikipedia_tieng_Viet.txt <-> Thac_Pongour__Wikipedia_tieng_Viet.txt: độ tương tự = 0.602\n",
      " - Thac_amb'ri__Wikipedia_tieng_Viet.txt <-> Thac_Prenn__Wikipedia_tieng_Viet.txt: độ tương tự = 0.57\n",
      " - Thac_Pongour__Wikipedia_tieng_Viet.txt <-> Thac_Prenn__Wikipedia_tieng_Viet.txt: độ tương tự = 0.555\n",
      "✅ Kết quả đã lưu vào similar_docs.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"🔍 Đang tính độ tương tự...\")\n",
    "similar_pairs = compute_similarities(minhashes)\n",
    "\n",
    "if similar_pairs:\n",
    "    print(\"\\n🧭 Các cặp tài liệu trùng hoặc giống nhau:\")\n",
    "    for d1, d2, s in similar_pairs:\n",
    "        print(f\" - {d1} <-> {d2}: độ tương tự = {s}\")\n",
    "    save_results(similar_pairs)\n",
    "else:\n",
    "    print(\"❌ Không có cặp tài liệu nào giống nhau vượt ngưỡng.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1087039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Phát hiện 1 cặp có Similarity > 0.8\n",
      "📂 Sẽ xóa 1 file trùng lặp:\n",
      "  - Cam_nang_du_lich_Lam_ong.txt\n",
      "❎ Hủy thao tác.\n",
      "\n",
      "✅ Đã xóa thành công 1/1 file có độ tương đồng > 0.8\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ==== CẤU HÌNH ====\n",
    "csv_path = \"similar_docs.csv\"  # File CSV chứa các cặp và độ tương đồng\n",
    "folder_path = \"../1.CollectingDocuments/data_clean\"  # Thư mục chứa các file .txt\n",
    "threshold = 0.8  # Ngưỡng tương đồng\n",
    "\n",
    "# ==== ĐỌC FILE CSV ====\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Lọc các cặp có độ tương đồng cao hơn ngưỡng\n",
    "high_sim = df[df[\"Similarity\"] > threshold]\n",
    "\n",
    "print(f\"🔍 Phát hiện {len(high_sim)} cặp có Similarity > {threshold}\")\n",
    "\n",
    "# ==== XÁC ĐỊNH DANH SÁCH FILE CẦN XÓA ====\n",
    "files_to_delete = set(high_sim[\"Document 2\"].tolist())  # chỉ xóa file thứ 2 trong mỗi cặp\n",
    "\n",
    "print(f\"📂 Sẽ xóa {len(files_to_delete)} file trùng lặp:\")\n",
    "\n",
    "for f in files_to_delete:\n",
    "    print(\"  -\", f)\n",
    "\n",
    "# ==== XÁC NHẬN TRƯỚC KHI XÓA ====\n",
    "confirm = input(\"\\n❓Bạn có chắc chắn muốn xóa các file này không? (y/n): \").lower()\n",
    "if confirm != \"y\":\n",
    "    print(\"❎ Hủy thao tác.\")\n",
    "    exit()\n",
    "\n",
    "# ==== XÓA FILE ====\n",
    "deleted = 0\n",
    "for f in files_to_delete:\n",
    "    file_path = os.path.join(folder_path, f)\n",
    "    if os.path.exists(file_path):\n",
    "        try:\n",
    "            os.remove(file_path)\n",
    "            deleted += 1\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Không thể xóa {f}: {e}\")\n",
    "\n",
    "print(f\"\\n✅ Đã xóa thành công {deleted}/{len(files_to_delete)} file có độ tương đồng > {threshold}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
